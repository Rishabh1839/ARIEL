{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ARIEL Engine**\n",
    "This program uses [linear regression](http://www.incertitudes.fr/book.pdf) in Python to forecast predictions based on public datasets. It will display accuracy (a number out of 100) and displays a graph using Matplotlib. We're using numpy which will help us support large multi-dimensional arrays along with a large collection of high level mathematical functions to operate on our arrays we will create for the data. Importing pickle is for serializing and de-serializing a python object structure. It's one way to convert a python object into a character stream. We import pandas library for data manipulation and analysis. Sci-Kit Learn helps us create our regression model, and finally we use matplotlib for plotting our data and visualization of our data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import quandl, math, datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "# from sklearn.svm.libsvm import cross_validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as data_plot\n",
    "from matplotlib import style\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are using a data-frame from Quandl which is a platform for economic and alternative data for development. I've used an API key to activate the API itself while it asks user for typing in a Stock Code for forecasting predictions and displaying accuracy. We then write the data to a file to save it and it displays user all the data from when the company was founded until present's stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using style\n",
    "style.use('ggplot')\n",
    "\n",
    "quandl.api_config.ApiConfig.api_key = 'h-FrEDCiZnh5cKM3Cuva'\n",
    "# getting random data from the api\n",
    "\n",
    "stockCode = input(\"Please enter the Stock Code for predictions: \")\n",
    "data = quandl.get('WIKI/' + stockCode)\n",
    "# writing\n",
    "writeFile = open(\"ARIELDataWrite.txt\", \"w\")\n",
    "writeFile.write(str(data))\n",
    "writeFile.close()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we insert columns for our data so we can get them labeled properly. The other part involves having to create a new variable which is going to be our High and Low Percent rate which will be [Adjust High] - [Adjust Close] / [Adjust Close] * 100.\n",
    "Our other Variable describes the percentage change which is [Adjust Close] - [Adjust Open] / [Adjust Open] * 100 and then printing them all out in our data for labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(data.head())\n",
    "# print(data.keys())\n",
    "# condenses the information\n",
    "# assert \"Forecasting\" in data\n",
    "data = data[['Adj. Open', 'Adj. High', 'Adj. Low', 'Adj. Close', 'Adj. Volume']]\n",
    "# creating new variable which is the high low percent\n",
    "data['HL_PCT'] = (data['Adj. High'] - data['Adj. Close']) / data['Adj. Close'] * 100.0\n",
    "# creating new variable which is the Percentage Change\n",
    "data['PCT_Change'] = (data['Adj. Close'] - data['Adj. Open']) / data['Adj. Open'] * 100.0\n",
    "\n",
    "data = data[['Adj. Close', 'HL_PCT', 'PCT_Change', 'Adj. Volume']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we forecast our dataset for predictions. The data.fillna is used to fill out our missing values to fill holes, alternately a series of values specifying which value to use for each of our index or column for the dataframe. Our forecast variable returns the ceiling of x as as float, where the smallest interger value is greater than or equal to x. The other function takes a scalar parameter which is called period, it represents the number of shifts to be made over our desired axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecasting out dataset\n",
    "forecastData = 'Adj. Close'\n",
    "data.fillna(-99999, inplace=True)\n",
    "print(data)\n",
    "# comment if necessary\n",
    "print(len(data))\n",
    "\n",
    "forecastOut = int(math.ceil(0.02*len(data)))\n",
    "\n",
    "data['Label'] = data[forecastData].shift(-forecastOut)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use data.drop to drop specified labels from rows or columns. This allows us to remove rows or columns by specifying the label names and the corresponding axis. We can also do it by specifying directly index or column names. We will be using our x parameter to standardize dataset along the axis by preprocessing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(data.drop(['Label'], 1))\n",
    "x = preprocessing.scale(x)\n",
    "xLately = x[-forecastOut: ]\n",
    "x = x[:-forecastOut]\n",
    "data.dropna(inplace = True)\n",
    "y = np.array(data['Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test and train the X and Y axis by using our model selection which is train_test_split. We use linear regression, it's a linear approach to our model that we will be creating to modelling the relationship between the scalar response and one or more explanatory variables. The relationships are modeled using a couple of linear predictor functions whose unknown model parameters  are estimated from the data itself. It focuses on the conditional probabilty distribution of the response given the values of the predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = model_selection.train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "frameControl = LinearRegression(n_jobs=-1)\n",
    "\n",
    "frameControl.fit(trainX, trainY)\n",
    "with open('linearregression.pickle', 'wb') as a:\n",
    "    pkl.dump(frameControl, a)\n",
    "\n",
    "inPickle = open('linearregression.pickle', 'rb')\n",
    "frameControl = pkl.load(inPickle)\n",
    "\n",
    "accuracy = frameControl.score(testX, testY) * 100.0\n",
    "\n",
    "setForecast = frameControl.predict(xLately)\n",
    "\n",
    "data['Forecasting the Data'] = np.nan\n",
    "last_date = data.iloc[-1].name\n",
    "last_unix = last_date.timestamp()\n",
    "one_day = 86400\n",
    "next_unix = last_unix + one_day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timestamp is used for the entries that make up a Date time index and other timeseries oriented data structures for our graph. This code here pretty much allows us to structure our data and show the data's past and present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in setForecast:\n",
    "    next_date = datetime.datetime.fromtimestamp(next_unix)\n",
    "    next_unix += one_day\n",
    "    data.loc[next_date] = [np.nan for _ in range(len(data.columns) - 1)] + [i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, we finally plot out our data using the matplotlib library for data visualization and it's prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data for visualization\n",
    "data['Adj. Close'].plot()\n",
    "data['Forecasting the Data'].plot()\n",
    "data_plot.legend(loc=4)\n",
    "data_plot.title('Stock Prediction for ' + stockCode)\n",
    "data_plot.xlabel('Date')\n",
    "data_plot.ylabel('price')\n",
    "data_plot.show()\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
